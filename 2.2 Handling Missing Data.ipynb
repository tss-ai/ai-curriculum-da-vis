{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSdZOwE6JFKM"
   },
   "source": [
    "# Handling Missing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BjL7FQBPJFKO"
   },
   "source": [
    "The difference between data found in many tutorials and data in the real world is that real-world data is rarely clean and homogeneous.\n",
    "In particular, many interesting datasets will have some amount of data missing.\n",
    "To make matters even more complicated, different data sources may indicate missing data in different ways.\n",
    "\n",
    "In this section, we will discuss some general considerations for missing data, discuss how Pandas chooses to represent it, and demonstrate some built-in Pandas tools for handling missing data in Python.\n",
    "Here and throughout the book, we'll refer to missing data in general as *null*, *NaN*, or *NA* values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kixo25DcJFKQ"
   },
   "source": [
    "## Missing Data in Pandas\n",
    "\n",
    "The way in which Pandas handles missing values is constrained by its reliance on the NumPy package, which does not have a built-in notion of NA values for non-floating-point data types.\n",
    "\n",
    "NumPy does have support for masked arrays – that is, arrays that have a separate Boolean mask array attached for marking data as \"good\" or \"bad.\"\n",
    "Pandas could have derived from this, but the overhead in both storage, computation, and code maintenance makes that an unattractive choice.\n",
    "\n",
    "With these constraints in mind, Pandas chose to use sentinels for missing data, and further chose to use two already-existing Python null values: the special floating-point ``NaN`` value, and the Python ``None`` object.\n",
    "This choice has some side effects, as we will see, but in practice ends up being a good compromise in most cases of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "52wX4VuiJFKU"
   },
   "source": [
    "### ``None``: Pythonic missing data\n",
    "\n",
    "The first sentinel value used by Pandas is ``None``, a Python singleton object that is often used for missing data in Python code.\n",
    "Because it is a Python object, ``None`` cannot be used in any arbitrary NumPy/Pandas array, but only in arrays with data type ``'object'`` (i.e., arrays of Python objects):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSdwDxcNJFKW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_TTtQXVVJFKZ",
    "outputId": "16b7c6c7-d80a-4fb1-e29c-34a33d03a236"
   },
   "outputs": [],
   "source": [
    "vals1 = np.array([1, None, 3, 4])\n",
    "vals1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BqUJqd8YJFKe"
   },
   "source": [
    "The use of Python objects in an array also means that if you perform aggregations like ``sum()`` or ``min()`` across an array with a ``None`` value, you will generally get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DsstUFI9JFKe",
    "outputId": "aeaa75f8-fda6-44cd-b2bd-063474beed4b"
   },
   "outputs": [],
   "source": [
    "vals1.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8g7wUHecJFKf"
   },
   "source": [
    "This reflects the fact that addition between an integer and ``None`` is undefined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMuJrgj-JFKg"
   },
   "source": [
    "### ``NaN``: Missing numerical data\n",
    "\n",
    "The other missing data representation, ``NaN`` (acronym for *Not a Number*), is different; it is a special floating-point value recognized by all systems that use the standard IEEE floating-point representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vSsd7KDlJFKg",
    "outputId": "b64e7561-90f5-4a0a-831a-29334161ecc7"
   },
   "outputs": [],
   "source": [
    "vals2 = np.array([1, np.nan, 3, 4]) \n",
    "vals2.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DnvsHLeIJFKh"
   },
   "source": [
    "Notice that NumPy chose a native floating-point type for this array: this means that unlike the object array from before, this array supports fast operations pushed into compiled code.\n",
    "You should be aware that ``NaN`` is a bit like a data virus–it infects any other object it touches.\n",
    "Regardless of the operation, the result of arithmetic with ``NaN`` will be another ``NaN``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uLXk_cT6JFKi",
    "outputId": "58a83ce7-9cb6-4ffc-a8fa-0b15815cff97"
   },
   "outputs": [],
   "source": [
    "1 + np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-8GFxnhDJFKj",
    "outputId": "77dec372-a1ab-4fce-845e-950c068f5d08"
   },
   "outputs": [],
   "source": [
    "0 * np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7a9qJ8-BJFKk"
   },
   "source": [
    "Note that this means that aggregates over the values are well defined (i.e., they don't result in an error) but not always useful:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "acFIubCHJFKl",
    "outputId": "d4a3af9b-fad8-4c89-9734-fc8e021ec60d"
   },
   "outputs": [],
   "source": [
    "vals2.sum(), vals2.min(), vals2.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rgpacF-SJFKl"
   },
   "source": [
    "NumPy does provide some special aggregations that will ignore these missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2c4TzEjuJFKm",
    "outputId": "6f13bad4-2cab-4230-e489-d3ed8f473219"
   },
   "outputs": [],
   "source": [
    "np.nansum(vals2), np.nanmin(vals2), np.nanmax(vals2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t3r2kWzWJFKm"
   },
   "source": [
    "Keep in mind that ``NaN`` is specifically a floating-point value; there is no equivalent NaN value for integers, strings, or other types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "If1IFboDJFKn"
   },
   "source": [
    "### NaN and None in Pandas\n",
    "\n",
    "``NaN`` and ``None`` both have their place, and Pandas is built to handle the two of them nearly interchangeably, converting between them where appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "70_jvmKiJFKn",
    "outputId": "0cd4f0be-e8ac-437a-dde6-9639588be51f"
   },
   "outputs": [],
   "source": [
    "pd.Series([1, np.nan, 2, None])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vXM8r7YrJFKn"
   },
   "source": [
    "For types that don't have an available sentinel value, Pandas automatically type-casts when NA values are present.\n",
    "For example, if we set a value in an integer array to ``np.nan``, it will automatically be upcast to a floating-point type to accommodate the NA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HC-NNKpJJFKo",
    "outputId": "f8f77a78-405d-4a28-d9ee-7bbfad5bf4de"
   },
   "outputs": [],
   "source": [
    "x = pd.Series(range(2), dtype=int)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J6Obgs_6JFKo",
    "outputId": "30c72cfc-f218-46a6-c4c4-08d264d60a19"
   },
   "outputs": [],
   "source": [
    "x[0] = None\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Ja0MERyJFKp"
   },
   "source": [
    "## Operating on Null Values\n",
    "\n",
    "As we have seen, Pandas treats ``None`` and ``NaN`` as essentially interchangeable for indicating missing or null values.\n",
    "To facilitate this convention, there are several useful methods for detecting, removing, and replacing null values in Pandas data structures.\n",
    "They are:\n",
    "\n",
    "- ``isnull()``: Generate a boolean mask indicating missing values\n",
    "- ``notnull()``: Opposite of ``isnull()``\n",
    "- ``dropna()``: Return a filtered version of the data\n",
    "- ``fillna()``: Return a copy of the data with missing values filled or imputed\n",
    "\n",
    "We will conclude this section with a brief exploration and demonstration of these routines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GgFe45O2JFKq"
   },
   "source": [
    "### Detecting null values\n",
    "Pandas data structures have two useful methods for detecting null data: ``isnull()`` and ``notnull()``.\n",
    "Either one will return a Boolean mask over the data. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O9cSBV11JFKq"
   },
   "outputs": [],
   "source": [
    "data = pd.Series([1, np.nan, 'hello', None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zm0eydlTJFKq",
    "outputId": "4d8c12b0-d3c0-4e41-9424-39cd6434a464"
   },
   "outputs": [],
   "source": [
    "data.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OWUpwh8tJFKr"
   },
   "source": [
    "Boolean masks can be used directly as a ``Series`` or ``DataFrame`` index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vXhUsaxZJFKr",
    "outputId": "91e940af-833b-4267-b92a-6d7e0900a64f"
   },
   "outputs": [],
   "source": [
    "data[data.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DkrlZDB4JFKs"
   },
   "source": [
    "The ``isnull()`` and ``notnull()`` methods produce similar Boolean results for ``DataFrame``s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dhzz30sFJFKs"
   },
   "source": [
    "### Dropping null values\n",
    "\n",
    "In addition to the masking used before, there are the convenience methods, ``dropna()``\n",
    "(which removes NA values) and ``fillna()`` (which fills in NA values). For a ``Series``,\n",
    "the result is straightforward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YNU_aMcoJFKt",
    "outputId": "04358d29-45db-43bc-81f2-6135b3758193"
   },
   "outputs": [],
   "source": [
    "data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s1L7DlhJFKt"
   },
   "source": [
    "For a ``DataFrame``, there are more options.\n",
    "Consider the following ``DataFrame``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QMNt9zDGJFKu",
    "outputId": "0d2d6af5-06f4-4f98-9746-7408d70d33b7"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1,      np.nan, 2],\n",
    "                   [2,      3,      5],\n",
    "                   [np.nan, 4,      6]])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvUSjnW9JFKu"
   },
   "source": [
    "We cannot drop single values from a ``DataFrame``; we can only drop full rows or full columns.\n",
    "Depending on the application, you might want one or the other, so ``dropna()`` gives a number of options for a ``DataFrame``.\n",
    "\n",
    "By default, ``dropna()`` will drop all rows in which *any* null value is present:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DuX1B51hJFKv",
    "outputId": "115d658a-6a6b-4e0c-9dd2-98aa81a5ca26"
   },
   "outputs": [],
   "source": [
    "df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_jojKldwJFKv"
   },
   "source": [
    "Alternatively, you can drop NA values along a different axis; ``axis=1`` drops all columns containing a null value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "28lXaPKJJFKw",
    "outputId": "edeff182-1bba-4545-e974-b12d17a1d881"
   },
   "outputs": [],
   "source": [
    "df.dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jSAcMmmyJFKw"
   },
   "source": [
    "But this drops some good data as well; you might rather be interested in dropping rows or columns with *all* NA values, or a majority of NA values.\n",
    "This can be specified through the ``how`` or ``thresh`` parameters, which allow fine control of the number of nulls to allow through.\n",
    "\n",
    "The default is ``how='any'``, such that any row or column (depending on the ``axis`` keyword) containing a null value will be dropped.\n",
    "You can also specify ``how='all'``, which will only drop rows/columns that are *all* null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCMpS2KBJFKx",
    "outputId": "40d3f9c7-6b99-4df3-b9cc-bd3b6fce3bc2"
   },
   "outputs": [],
   "source": [
    "df[3] = np.nan\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QVE-uqPyJFKy",
    "outputId": "4352d2b3-bbc0-43ac-fc90-c43a5f1cd40c"
   },
   "outputs": [],
   "source": [
    "df.dropna(axis='columns', how='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9tu6YD5bJFKy"
   },
   "source": [
    "For finer-grained control, the ``thresh`` parameter lets you specify a minimum number of non-null values for the row/column to be kept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z7nxs0wbJFKz",
    "outputId": "4ef6b6a6-25d1-4212-a685-e7bc31e3b2d4"
   },
   "outputs": [],
   "source": [
    "df.dropna(axis='rows', thresh=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ug9D1XJsJFKz"
   },
   "source": [
    "Here the first and last row have been dropped, because they contain only two non-null values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SC42gKNwJFK0"
   },
   "source": [
    "### Filling null values\n",
    "\n",
    "Sometimes rather than dropping NA values, you'd rather replace them with a valid value.\n",
    "This value might be a single number like zero, or it might be some sort of imputation or interpolation from the good values.\n",
    "You could do this in-place using the ``isnull()`` method as a mask, but because it is such a common operation Pandas provides the ``fillna()`` method, which returns a copy of the array with the null values replaced.\n",
    "\n",
    "Consider the following ``Series``:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TY1Bkly0JFK0",
    "outputId": "d84b63e3-eb33-4685-9cda-a4f1a0ed390c"
   },
   "outputs": [],
   "source": [
    "data = pd.Series([1, np.nan, 2, None, 3], index=list('abcde'))\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWjHIPwEJFK0"
   },
   "source": [
    "We can fill NA entries with a single value, such as zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kQc_-dAuJFK1",
    "outputId": "fb7faf37-b7b7-4e93-940c-09fb8b17fc5f"
   },
   "outputs": [],
   "source": [
    "data.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SeBQ1fSlJFK1"
   },
   "source": [
    "We can specify a forward-fill to propagate the previous value forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qpiChAmsJFK1",
    "outputId": "e2dd40a4-18f7-4bb5-cca5-8b7ae7f9bcb3"
   },
   "outputs": [],
   "source": [
    "# forward-fill\n",
    "data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y0KpuOgPJFK2"
   },
   "source": [
    "Or we can specify a back-fill to propagate the next values backward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fnz9SNv7JFK2",
    "outputId": "e59ec192-a399-4173-e917-5218c30ef52a"
   },
   "outputs": [],
   "source": [
    "# back-fill\n",
    "data.fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "b3BLoiBtJFK3"
   },
   "source": [
    "For ``DataFrame``s, the options are similar, but we can also specify an ``axis`` along which the fills take place:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGU1poQeJFK3",
    "outputId": "7e3e3a95-0c98-433d-e973-cb936f076bf7"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u6--8nfDJFK3",
    "outputId": "2d307746-4dde-4d86-a507-34c83d7864f1"
   },
   "outputs": [],
   "source": [
    "df.fillna(method='ffill', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PlqiIegiJFK4"
   },
   "source": [
    "Notice that if a previous value is not available during a forward fill, the NA value remains."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
